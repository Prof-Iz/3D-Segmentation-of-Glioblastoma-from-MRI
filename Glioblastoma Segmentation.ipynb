{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Segmentation of Brain Tumor\n",
    "\n",
    "This document is to propose a 2D methodology instead of treating it as a 3D input.\n",
    "\n",
    "\n",
    "## Loading the Dataset\n",
    "The dataset used is the BraTS 2020 Dataset.\n",
    "\n",
    "The Dataset Contains the Following Scans per case:\n",
    "\n",
    "T1: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\n",
    "\n",
    "T1c: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\n",
    "\n",
    "T2: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\n",
    "\n",
    "FLAIR: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\n",
    "\n",
    "So for training T1ce, T2 and FLAIR will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previewing the MRI Data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path, listdir\n",
    "from monai.data import Dataset\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Compose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare list of All training Cases\n",
    "TRAINING_DATASET_PATH = \"./MICCAI_BraTS2020_TrainingData/\"\n",
    "cases = [path.join(TRAINING_DATASET_PATH, x) for x in listdir(TRAINING_DATASET_PATH)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a list of dictionaries of T1CE, T2, FLAIR and Ground Truth Segmentation for preparing the Dataset to be used in the Data Loader \n",
    "mri_cases_dictionary = [\n",
    "    {\n",
    "        \"image\": [\n",
    "            path.join(case, f\"{path.split(case)[-1]}_t1ce.nii.gz\"),\n",
    "            path.join(case, f\"{path.split(case)[-1]}_t2.nii.gz\"),\n",
    "            path.join(case, f\"{path.split(case)[-1]}_flair.nii.gz\"),\n",
    "        ],\n",
    "        \"seg\": path.join(case, f\"{path.split(case)[-1]}_seg.nii.gz\"),\n",
    "    }\n",
    "    for case in cases[:30]  #! Only 30 cases taken as test slice\n",
    "]\n",
    "\n",
    "# Transform data such as from niftii into Tensors\n",
    "transform_training_dataset = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\",\"seg\"])\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset_training = Dataset(mri_cases_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./MICCAI_BraTS2020_TrainingData/BraTS20_Training_001\\\\BraTS20_Training_001_t1ce.nii.gz',\n",
       " './MICCAI_BraTS2020_TrainingData/BraTS20_Training_001\\\\BraTS20_Training_001_t2.nii.gz',\n",
       " './MICCAI_BraTS2020_TrainingData/BraTS20_Training_001\\\\BraTS20_Training_001_flair.nii.gz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_training[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import Dataset, CacheDataset,PersistentDataset, decollate_batch, list_data_collate\n",
    "from glob import glob\n",
    "from os import path, listdir\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    SpatialPadd,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    Spacingd,\n",
    "    RandSpatialCropd,\n",
    "    RandFlipd,\n",
    "    MapTransform,\n",
    "    CropForegroundd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandCropByLabelClassesd,\n",
    "    RandSpatialCropSamplesd\n",
    ")\n",
    "\n",
    "from monai.data import partition_dataset\n",
    "from monai.networks.nets import UNet,UNETR, SegResNet, BasicUnet\n",
    "from monai.losses import TverskyLoss, DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utilities.split_data as split_data\n",
    "plt.style.use(['science','ieee'])\n",
    "%matplotlib inline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37bd13aa3d924eb96db98b00aa626978b2fce1020e2653180f4604a647daf9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
