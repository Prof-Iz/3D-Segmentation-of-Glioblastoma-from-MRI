{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.transforms import LoadImaged, MapTransform, Compose, ToNumpyd\n",
    "from monai.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "Validation_Cases = list(glob.glob(\"./MICCAI_BraTS2020_TrainingData/BraTS20*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_cases = []\n",
    "\n",
    "for case in Validation_Cases:\n",
    "    try:\n",
    "        t1 = list(glob.glob(f\"{case}/*t1.nii.gz\"))\n",
    "        t1ce = list(glob.glob(f\"{case}/*t1ce.nii.gz\"))\n",
    "        t2 = list(glob.glob(f\"{case}/*t2.nii.gz\"))\n",
    "        flair = list(glob.glob(f\"{case}/*flair.nii.gz\"))\n",
    "        seg = glob.glob(f\"{case}/*seg.nii.gz\")[0]\n",
    "\n",
    "        img = t1 + t1ce + t2 + flair\n",
    "\n",
    "        d = {\"image\": img, \"seg\": seg}\n",
    "        experiment_cases.append(d)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertLabelsIntoOneHotd(MapTransform):\n",
    "    \"\"\"Takes input tensor of segmentation which contains\n",
    "    values in set (0,1,2,4) where\\n\n",
    "    0 -> Background/Normal\\n\n",
    "    1 -> Non- Enhancing Tumor Core\\n\n",
    "    2 -> Edema\\n\n",
    "    4 -> Enhancing tumor core\\n\n",
    "\n",
    "    and returns a one hot encoded 3 channel tensor where\n",
    "    1st Channel -> Whole tumor (1,2 and 4)\n",
    "    2nd Channel -> Tumor Core (1 and 4)\n",
    "    3rd Channel -> Enhancing Tumor core (4)\n",
    "    \"\"\"\n",
    "    def __call__(self, data):\n",
    "        data_dict = dict(data)\n",
    "        for key in self.keys:\n",
    "            one_hot_encode_array = [\n",
    "                torch.logical_or(\n",
    "                    torch.logical_or(data_dict[key] == 1, data_dict[key] == 2),\n",
    "                    data_dict[key] == 4,\n",
    "                ), # Whole Tumor\n",
    "                torch.logical_or(data_dict[key] == 1, data_dict[key] == 4), # Tumor Core\n",
    "                data_dict[key] == 4, # Enhancing Core\n",
    "            ]\n",
    "            data_dict[key] = torch.stack(one_hot_encode_array, axis=0).astype(torch.int32)\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_for_analysis = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"seg\"]),\n",
    "        ConvertLabelsIntoOneHotd(keys=\"seg\"),\n",
    "        ToNumpyd(keys=[\"image\", \"seg\"])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(experiment_cases,transform_for_analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textural Analysis\n",
    "\n",
    "1. Take GLCM from Tumor Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to find boundary from segmentation\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "case = 25\n",
    "wt = dataset[case]['seg'][0]\n",
    "tc = dataset[case]['seg'][1]\n",
    "et = dataset[case]['seg'][2]\n",
    "\n",
    "t1 = dataset[case]['image'][0]\n",
    "t1ce = dataset[case]['image'][1]\n",
    "t2 = dataset[case]['image'][2]\n",
    "flair = dataset[case]['image'][3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 WT blob found\n",
      "1 TC blob found\n",
      "1 ET blob found\n"
     ]
    }
   ],
   "source": [
    "blob_wt = ndimage.find_objects(wt)\n",
    "print(f\"{len(blob_wt)} WT blob found\")\n",
    "blob_tc = ndimage.find_objects(tc)\n",
    "print(f\"{len(blob_tc)} TC blob found\")\n",
    "blob_et = ndimage.find_objects(et)\n",
    "print(f\"{len(blob_et)} ET blob found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Whole Tumor\n",
      "Blob 0: coordinate (30.557043041114397, 53.65276439778981, 42.876817371469066) and 180.618 cm^3\n",
      "\n",
      "For Tumor Core\n",
      "Blob 0: coordinate (21.879299974221638, 32.3802308595652, 25.608541231060062) and 34.913 cm^3\n",
      "\n",
      "For Enhancing Tumor\n",
      "Blob 0: coordinate (23.28733738807231, 32.01900658895084, 27.14660415610745) and 23.676 cm^3\n"
     ]
    }
   ],
   "source": [
    "# Finding Center of Mass and Volume\n",
    "\n",
    "print(\"For Whole Tumor\")\n",
    "for i,blob in enumerate(blob_wt):\n",
    "    print(f\"Blob {i}: coordinate {ndimage.center_of_mass(wt[blob])} and {np.count_nonzero(wt[blob]) / 10**3} cm^3\")\n",
    "\n",
    "\n",
    "print(\"\\nFor Tumor Core\")\n",
    "for i,blob in enumerate(blob_tc):\n",
    "    print(f\"Blob {i}: coordinate {ndimage.center_of_mass(tc[blob])} and {np.count_nonzero(tc[blob]) / 10**3} cm^3\")\n",
    "\n",
    "\n",
    "print(\"\\nFor Enhancing Tumor\")\n",
    "for i,blob in enumerate(blob_et):\n",
    "    print(f\"Blob {i}: coordinate {ndimage.center_of_mass(et[blob])} and {np.count_nonzero(et[blob]) / 10**3} cm^3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLCM\n",
    "\n",
    "# Based on https://github.com/Prof-Iz/GLCM-from-3D-NumPy-Input\n",
    "\n",
    "def glcm_3d(input: np.ndarray, delta: tuple[int] = (1, 1, 1), d: int = 1):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        input (np.ndarray): input array. 3D. dtype int\n",
    "        delta (tuple[int], optional): Direction vector from pixel. Defaults to (1, 1, 1).\n",
    "        d (int, optional): Distance to check for neighbouring channel. Defaults to 1.\n",
    "\n",
    "    Raises:\n",
    "        Exception: if input is not of type dint or is not 3D\n",
    "\n",
    "    Returns:\n",
    "        _type_: GLCM Matrix\n",
    "    \"\"\"\n",
    "\n",
    "    if 'int' not in input.dtype.__str__():\n",
    "        raise Exception(\"Input should be of dtype Int\")\n",
    "\n",
    "    if len(input.shape) != 3:\n",
    "        raise Exception(\"Input should be 3 dimensional\")\n",
    "\n",
    "    offset = (delta[0] * d, delta[1] * d, delta[2] * d)  # offset from each pixel\n",
    "\n",
    "    x_max, y_max, z_max = input.shape  # boundary conditions during enumeration\n",
    "\n",
    "    levels = input.max() + 1 # 0:1:n assume contn range of pixel values\n",
    "\n",
    "    results = np.zeros((levels, levels))  # initialise results error\n",
    "\n",
    "\n",
    "    for i, v in np.ndenumerate(input):\n",
    "        x_offset = i[0] + offset[0]\n",
    "        y_offset = i[1] + offset[1]\n",
    "        z_offset = i[2] + offset[2]\n",
    "\n",
    "        if (x_offset >= x_max) or (y_offset >= y_max) or (z_offset >= z_max):\n",
    "            # if offset out of boundary skip\n",
    "            continue\n",
    "\n",
    "        value_at_offset = input[x_offset, y_offset, z_offset]\n",
    "\n",
    "        results[v, value_at_offset] += 1\n",
    "\n",
    "    return results / levels**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 110, 79)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find GLCM for a blob in WT\n",
    "\n",
    "wt_tumor_boundary_t1    = t1[blob_wt[0]]\n",
    "wt_tumor_boundary_t1ce  = t1ce[blob_wt[0]]\n",
    "wt_tumor_boundary_t2    = t2[blob_wt[0]]\n",
    "wt_tumor_boundary_flair = flair[blob_wt[0]]\n",
    "\n",
    "wt_tumor_boundary_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm = glcm_3d(np.int32(wt_tumor_boundary_t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(P):\n",
    "    return P / np.sum(P)\n",
    "\n",
    "\n",
    "def graycoprops(P):\n",
    "\n",
    "    P = normalise(P)\n",
    "\n",
    "    energy = np.sum(P**2)\n",
    "\n",
    "    idx = np.where(P > 0)\n",
    "\n",
    "    homogeneity = np.sum(P[idx] / (1 + (idx[0] - idx[1]) ** 2))\n",
    "\n",
    "    contrast = np.sum(P[idx] * (idx[0] - idx[1]) ** 2)\n",
    "\n",
    "    entropy = np.sum(-P[idx] * np.log(P[idx]))\n",
    "\n",
    "    # for correlation\n",
    "\n",
    "    mu = np.sum(idx[0] * P[idx])\n",
    "\n",
    "    sigma_square = np.sum(P[idx] * (idx[0] - mu) ** 2)\n",
    "\n",
    "    correlation = np.sum((P[idx] * (idx[0] - mu) * (idx[1] - mu)) / sigma_square)\n",
    "\n",
    "    return {\n",
    "        \"energy\": energy,\n",
    "        \"homogeneity\": homogeneity,\n",
    "        \"contrast\": contrast,\n",
    "        \"entropy\": entropy,\n",
    "        \"correlation\": correlation,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'energy': 0.010458012361037416, 'homogeneity': 0.14261134493343397, 'contrast': 7161.607885927293, 'entropy': 10.093394917491178, 'correlation': 0.9076729367777118}\n"
     ]
    }
   ],
   "source": [
    "print(graycoprops(glcm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37bd13aa3d924eb96db98b00aa626978b2fce1020e2653180f4604a647daf9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
