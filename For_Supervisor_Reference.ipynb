{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Segmentation of Brain Tumor\n",
    "\n",
    "\n",
    "## Loading the Dataset\n",
    "The dataset used is the BraTS 2020 Dataset.\n",
    "\n",
    "The Dataset Contains the Following Scans per case:\n",
    "\n",
    "T1: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\n",
    "\n",
    "T1c: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\n",
    "\n",
    "T2: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\n",
    "\n",
    "FLAIR: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries.\n",
    "\n",
    "**Essential**\n",
    "1. [Pytorch with CuDA](https://pytorch.org/get-started/locally/) \n",
    "1. Monai (all or with nibabel) ex: `pip install 'monai[all]'`\n",
    "1. Pandas\n",
    "1. Numpy\n",
    "1. Scikit Learn\n",
    "\n",
    "*Note: If any libraries are missing during run time, read the error message to install them*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "from os import path, listdir\n",
    "import os\n",
    "import monai\n",
    "from monai.data import (Dataset, list_data_collate, DataLoader, decollate_batch, PersistentDataset)\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    Compose,\n",
    "    MapTransform,\n",
    "    Orientationd,\n",
    "    ToMetaTensord,  # ? same as ensuretyped?\n",
    "    EnsureChannelFirstd,\n",
    "    NormalizeIntensityd,\n",
    "    Spacingd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    ")\n",
    "\n",
    "from monai.networks.nets import  UNet\n",
    "from monai.losses import  DiceCELoss\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.optimizers import Novograd, WarmupCosineSchedule\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeding to ensure reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.utils.misc.set_determinism(1607)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Function to call to free allocated GPU memory in between trainining different models as PyTorch does not free it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def clear_gpu_cache():\n",
    "    \"\"\"Clear the PyTorch GPU Allocation if an OOM error occurs.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(\"Deleting Model\")\n",
    "        global model\n",
    "        del model\n",
    "    except NameError as e:\n",
    "        print(f\"Model Already Cleared\")\n",
    "\n",
    "    print(\"Collecting Garbage\")\n",
    "    gc.collect()\n",
    "    print(\"Clearing CUDA Cache\")\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Dataset\n",
    "\n",
    "As per [University of Pennsylvania](https://www.med.upenn.edu/cbica/brats2020/data.html):\n",
    "\n",
    "All BraTS multimodal scans are available as NIfTI files (.nii.gz) and describe a) native (T1) and b) post-contrast T1-weighted (T1Gd), c) T2-weighted (T2), and d) T2 Fluid Attenuated Inversion Recovery (T2-FLAIR) volumes, and were acquired with different clinical protocols and various scanners from multiple (n=19) institutions, mentioned as data contributors here.\n",
    "\n",
    "All the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise the GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2), and the necrotic and non-enhancing tumor core (NCR/NET — label 1), as described both in the BraTS 2012-2013 TMI paper(opens in a new window) and in the latest BraTS summarizing paper. The provided data are distributed after their pre-processing, i.e., *co-registered to the same anatomical template*, interpolated to the *same resolution (1 mm^3)* and *skull-stripped*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to randomly split the dataset into training and testing, however ensuring that the ratio of High Grade to Low Grade in both split are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def encode_lgg_hgg(x):\n",
    "    \"\"\"Encode LGG and HGG as 0 and 1 for stratification\n",
    "\n",
    "    Args:\n",
    "        x (str): LGG or HGG in Dataframe\n",
    "\n",
    "    Returns:\n",
    "        int: encodes 0 for LGG and 1 for HGG\n",
    "    \"\"\"\n",
    "    return 0 if x == \"LGG\" else 1\n",
    "\n",
    "\n",
    "def train_val_test_dataset(data_path: str):\n",
    "    \"\"\"From 100% Cases take 20% cases as Validation.\n",
    "    Take the remaining 80% cases as training\n",
    "\n",
    "    Stratification done on data to ensure that the classes are balanced.\n",
    "\n",
    "    Args:\n",
    "        data_path (str, optional): Path to Name Mapping File provided by BraTS.\n",
    "\n",
    "    Returns:\n",
    "        training, validation, testing: list of case names split into training, validation and testing.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(data_path)\n",
    "    data = data[[\"Grade\", \"BraTS_2020_subject_ID\"]]\n",
    "    data.Grade = data[\"Grade\"].map(encode_lgg_hgg)\n",
    "    (training, validation, train_check, val_check,) = train_test_split(\n",
    "        data.BraTS_2020_subject_ID.to_list(),\n",
    "        data.Grade.to_numpy(),\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=data.Grade.to_numpy(),\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Total Samples = {len(training)+len(validation)}\\n\n",
    "    Ratio of LGG:HGG in {len(training)} Training Samples:\n",
    "    \\t Ratio = {np.count_nonzero(train_check==0)/np.count_nonzero(train_check==1):.2f}\\n\n",
    "\n",
    "    Ratio of LGG:HGG in {len(validation)} Validation Samples:\n",
    "    \\t Ratio = {np.count_nonzero(val_check==0)/np.count_nonzero(val_check==1):.2f}\\n\n",
    "    \n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    return (training, validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Total Samples = 369\n",
      "\n",
      "    Ratio of LGG:HGG in 295 Training Samples:\n",
      "    \t Ratio = 0.26\n",
      "\n",
      "\n",
      "    Ratio of LGG:HGG in 74 Validation Samples:\n",
      "    \t Ratio = 0.25\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Prepare list of All training Cases\n",
    "TRAINING_DATASET_PATH = r\"./MICCAI_BraTS2020_TrainingData/\"\n",
    "NAME_MAPPING = r\"./MICCAI_BraTS2020_TrainingData/name_mapping.csv\"\n",
    "\n",
    "# Function returns names of cases to be used\n",
    "train_cases, val_cases = train_val_test_dataset(NAME_MAPPING)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare mapping to convert into PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases = [\n",
    "    {\n",
    "        \"image\": [\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_t1.nii.gz\"),\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_t1ce.nii.gz\"),\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_t2.nii.gz\"),\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_flair.nii.gz\"),\n",
    "        ],\n",
    "        \"seg\": path.join(\n",
    "            TRAINING_DATASET_PATH, case, f\"{case}_seg.nii.gz\"\n",
    "        ),\n",
    "    }\n",
    "    for case in train_cases\n",
    "]\n",
    "\n",
    "val_cases = [\n",
    "    {\n",
    "        \"image\": [\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_t1.nii.gz\"),\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_t1ce.nii.gz\"),\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_t2.nii.gz\"),\n",
    "            path.join(TRAINING_DATASET_PATH, case, f\"{case}_flair.nii.gz\"),\n",
    "        ],\n",
    "        \"seg\": path.join(\n",
    "            TRAINING_DATASET_PATH, case, f\"{case}_seg.nii.gz\"\n",
    "        ),\n",
    "    }\n",
    "    for case in val_cases\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to the Data Loader will be a dictionary mapping the names of where the scans are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': ['./MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\\\\BraTS20_Training_219_t1.nii.gz',\n",
       "   './MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\\\\BraTS20_Training_219_t1ce.nii.gz',\n",
       "   './MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\\\\BraTS20_Training_219_t2.nii.gz',\n",
       "   './MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\\\\BraTS20_Training_219_flair.nii.gz'],\n",
       "  'seg': './MICCAI_BraTS2020_TrainingData/BraTS20_Training_219\\\\BraTS20_Training_219_seg.nii.gz'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cases[:1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the goal is to segment Whole Tumor, Tumor Core and Enhancing Tumor, the segmentation Niftii file has a special transformation applied to it as seen in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertLabelsIntoOneHotd(MapTransform):\n",
    "    \"\"\"Takes input tensor of segmentation which contains\n",
    "    values in set (0,1,2,4) where\\n\n",
    "    0 -> Background/Normal\\n\n",
    "    1 -> Non- Enhancing Tumor Core\\n\n",
    "    2 -> Edema\\n\n",
    "    4 -> Enhancing tumor core\\n\n",
    "\n",
    "    and returns a one hot encoded 3 channel tensor where\n",
    "    1st Channel -> Whole tumor (1,2 and 4)\n",
    "    2nd Channel -> Tumor Core (1 and 4)\n",
    "    3rd Channel -> Enhancing Tumor core (4)\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        data_dict = dict(data)\n",
    "        for key in self.keys:\n",
    "            one_hot_encode_array = [\n",
    "                torch.logical_or(\n",
    "                    torch.logical_or(data_dict[key] == 1, data_dict[key] == 2),\n",
    "                    data_dict[key] == 4,\n",
    "                ),  # Whole Tumor\n",
    "                torch.logical_or(data_dict[key] == 1, data_dict[key] == 4),  # Tumor Core\n",
    "                data_dict[key] == 4,  # Enhancing Core\n",
    "                \n",
    "            ]\n",
    "        data_dict[key] = torch.stack(one_hot_encode_array, axis=0).astype(torch.float32)\n",
    "        return data_dict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations during training and later during validation are declared below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_validation_dataset = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"seg\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        ConvertLabelsIntoOneHotd(keys=\"seg\"),\n",
    "        ToMetaTensord([\"image\", \"seg\"]),\n",
    "        Orientationd(keys=[\"image\", \"seg\"], axcodes=\"RAS\"),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_data_loader = DataLoader(\n",
    "    Dataset(\n",
    "        val_cases, transform_validation_dataset,\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "transform_training_dataset = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"image\", \"seg\"]),\n",
    "            EnsureChannelFirstd(keys=[\"image\"]),\n",
    "            ConvertLabelsIntoOneHotd(keys=\"seg\"),\n",
    "            ToMetaTensord([\"image\", \"seg\"]),\n",
    "            Orientationd(keys=[\"image\", \"seg\"], axcodes=\"RAS\"),\n",
    "            NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "            RandCropByPosNegLabeld(\n",
    "                keys=[\"image\", \"seg\"],\n",
    "                spatial_size=(128, 128, 128),\n",
    "                label_key=\"seg\",\n",
    "                neg=0,\n",
    "                num_samples=2,\n",
    "            ),\n",
    "            RandFlipd(keys=[\"image\", \"seg\"], prob=0.5, spatial_axis=0),\n",
    "            RandFlipd(keys=[\"image\", \"seg\"], prob=0.5, spatial_axis=1),\n",
    "            RandFlipd(keys=[\"image\", \"seg\"], prob=0.5, spatial_axis=2),\n",
    "            RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "            RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    Dataset(\n",
    "        train_cases,\n",
    "        transform_training_dataset,\n",
    "    ),\n",
    "    shuffle=True,\n",
    "    batch_size=2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about the above transformations\n",
    "- During validation the data transformation stops upto normalisation. It does not include any random cropping.\n",
    "- During Training, in each epoch, two random sample of size (128,128,128) is taken from each input.\n",
    "- Batch size or the number of samples maybe increased or asjusted as per system resources available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TensorBoard Logger is instantiated to log metrics and other features during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Model\n",
      "Model Already Cleared\n",
      "Collecting Garbage\n",
      "Clearing CUDA Cache\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "clear_gpu_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Period is set to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation is set to occur at every 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_interval = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training device is auto set to GPU or CPU depending on availability. Note that certain tasks are coded to use CPU, such as during sliding window inference as my system cannot handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UNet Model is instantiated from MONAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=4,\n",
    "    out_channels=3,\n",
    "    strides=(2, 2, 2),\n",
    "    channels=[16,32,64,128],\n",
    "    num_res_units=2,\n",
    ").to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimiser is initialised. I use Novograd, but you may use any other as you see fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Novograd(model.parameters(), weight_decay=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A learning rate scheduler is used where the first 10% of epochs are used to warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = WarmupCosineSchedule(\n",
    "    optimizer,\n",
    "    warmup_steps=int(epochs / 10),\n",
    "    warmup_multiplier=1e-10,\n",
    "    t_total=epochs,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function is initialised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceCELoss(sigmoid=True, squared_pred=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Automatic Mixed Precision is used to increase training speed and reduce memory consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for inference is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input):\n",
    "    \"\"\"Do Sliding Window Inference on input tensor\n",
    "    To avoid OOM Error, Input Model done on CPU.\n",
    "    Patch taken from input and its inference done on GPU\n",
    "    to speed up inference time.\n",
    "\n",
    "    Args:\n",
    "        input: Full input to pass in the model. For the case\n",
    "        of this project size => (3,240,240,155)\n",
    "    \"\"\"\n",
    "\n",
    "    def _compute(input):\n",
    "        return sliding_window_inference(\n",
    "            inputs=input.to(\"cpu\"),\n",
    "            roi_size=(128,128,128),\n",
    "            sw_batch_size=1,\n",
    "            predictor=model,\n",
    "            overlap=0.5,\n",
    "            padding_mode=\"constant\",\n",
    "            sw_device=\"cuda:0\",\n",
    "            device=\"cpu\",\n",
    "            mode=\"constant\",\n",
    "        )\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        return _compute(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Inference the output from the model undergoes post processing. Namely,\n",
    "- Sigmoid Activation\n",
    "- Convert the sigmoid values to Discrete 0 or 1 based on threshold value. Can adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processing_validation = Compose(\n",
    "    [Activations(sigmoid=True), AsDiscrete(threshold=0.5)]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DICE and Hausdaurff metric are prepared. Other metrics may be instantiated as needed. \n",
    "Metric with _batch are reduced (mean) on the Batch Channel [Batch,Channel,Dims..] and later aggregated on each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
    "\n",
    "hausdorff_metric = HausdorffDistanceMetric(\n",
    "    include_background=True, distance_metric='euclidean',\n",
    "    reduction=\"mean\"\n",
    ")\n",
    "\n",
    "hausdorff_metric_batch = HausdorffDistanceMetric(\n",
    "    include_background=True, distance_metric='euclidean',\n",
    "    reduction=\"mean_batch\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, If you already have a checkpoint file (model weights from a previous session). You may load them to continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     chk = torch.load(\"nameoffile.pth\")\n",
    "#     model.load_state_dict(chk['model'])\n",
    "#     optimizer.load_state_dict(chk['optimiser'])\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise a global variable to keep track of best_metric score so that the model state can be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_metric = -1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model for Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    logger.add_scalar(\"Learning_Rate\", optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "    for batch_data in tqdm(train_data_loader):\n",
    "\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"seg\"].to(device),\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        step += 1\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    epoch_loss_value = epoch_loss / step\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    logger.add_scalar(\"Training/Loss\", epoch_loss_value, epoch)\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(val_data_loader):\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"],\n",
    "                    val_data[\"seg\"].to(device),\n",
    "                )\n",
    "\n",
    "                val_outputs = inference(val_inputs)\n",
    "\n",
    "                val_outputs = [\n",
    "                    post_processing_validation(i)\n",
    "                    for i in decollate_batch(val_outputs.to(device))\n",
    "                ]\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            metric = dice_metric.aggregate().item()\n",
    "\n",
    "            metric_batch = dice_metric_batch.aggregate()\n",
    "            metric_wt = metric_batch[0].item()\n",
    "            metric_tc = metric_batch[1].item()\n",
    "            metric_et = metric_batch[2].item()\n",
    "\n",
    "\n",
    "            hausdorff_avg = hausdorff_metric.aggregate().item()\n",
    "            hausdorff_batch = hausdorff_metric_batch.aggregate()\n",
    "            hausdorff_wt = hausdorff_batch[0].item()\n",
    "            hausdorff_tc = hausdorff_batch[1].item()\n",
    "            hausdorff_et = hausdorff_batch[2].item()\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model\": model.state_dict(),\n",
    "                        \"optimiser\": optimizer.state_dict(),\n",
    "                        \"scheduler\": lr_scheduler.state_dict(),\n",
    "                        \"best_metric_epoch\": epoch,\n",
    "                        \"best_metric\": best_metric\n",
    "                    },\n",
    "                    f\"./best_model_DICE_{int(metric*100)}.pth\",\n",
    "                )\n",
    "\n",
    "            logger.add_scalar(\"DICE/Average\", metric, epoch)\n",
    "            logger.add_scalar(\"DICE/WT\", metric_wt, epoch)\n",
    "            logger.add_scalar(\"DICE/TC\", metric_tc, epoch)\n",
    "            logger.add_scalar(\"DICE/ET\", metric_et, epoch)\n",
    "\n",
    "            logger.add_scalar(\"Hausdaurff/Average\", hausdorff_avg, epoch)\n",
    "            logger.add_scalar(\"Hausdaurff/WT\", hausdorff_wt, epoch)\n",
    "            logger.add_scalar(\"Hausdaurff/TC\", hausdorff_tc, epoch)\n",
    "            logger.add_scalar(\"Hausdaurff/ET\", hausdorff_et, epoch)\n",
    "\n",
    "\n",
    "            dice_metric.reset()\n",
    "            dice_metric_batch.reset()\n",
    "            hausdorff_metric.reset()\n",
    "            hausdorff_metric_batch.reset()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Inference and Analysis from the Model Refer to the [Analysis Notebook](Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37bd13aa3d924eb96db98b00aa626978b2fce1020e2653180f4604a647daf9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
